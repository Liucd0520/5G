{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7756c86b-eef2-4281-a60b-bb795ae54a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LassoCV, LogisticRegression, Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db0c6be-7971-4451-9cea-e64d9c091727",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stat_t_u(var_df):\n",
    "    \"\"\"\n",
    "    T检验/U检验: 同时对连续变量进行两个检验\n",
    "    # T检验分为 1. 单样本T检验（比如抽样100人身高和全国人的平均身高167cm 是否有显著差异）\n",
    "    #          2. 独立样本T检验 （也叫双样本T检验，比如全班男女身高是否有显著差异，这里的男女是两个独立变量）\n",
    "    #          3. 联合样本T检验（比如吃饭前后班级同学的血糖浓度有没有变化，是针对同一批患者，且数量必须一致，研究时间等相关性）\n",
    "    # 检验分为单侧检验和双侧检验，1. 双侧检验是两个变量绝对值的显著性 2.单侧是仅大于或小于的情况\n",
    "    # 其中独立样本T检验的适用条件为：\n",
    "    # 独立样本t检验，用于两个完全独立的、符合 正态分布的样本的均数比较。所以使用前先进性正态性和方差齐性检验\n",
    "    # 根据两样本的方差是否相等，可分为：总体方差相等的t检验总体方差不等的t检验\n",
    "    # 但是对于大样本，不一定要满足正态性参见《数据不满足正态分布，到底能不能用t检验？》\n",
    "    \n",
    "    # Mann-Whitney U 检验是零假设的非参数检验，要求样本 x 的分布与样本 y 的分布相同。\n",
    "    # U检验不需要数据满足正态分布，而T检验需要满足。\n",
    "\n",
    "    \n",
    "    var_df: 输入的DataFrame 包含特征和标签\n",
    "    return : 返回U检验保留的特征\n",
    "    \"\"\"\n",
    "    # 对连续变量进行 独立样本T检验\n",
    "    del_Ustat_var, contain_Ustat_var = [], []\n",
    "    del_Tstat_var, contain_Tstat_var = [], []\n",
    "    contain_Ustat_p = []\n",
    "    contain_Tstat_p = []\n",
    "    \n",
    "    for column_name in var_df.columns[:-1]:\n",
    "        # print(column_name, end=' ')\n",
    "        \n",
    "        select_df = var_df[[column_name, 'bpCR']].dropna()  # 非空值计算\n",
    "    #     select_df = var_df[[column_name, 'bpCR']].fillna(var_df[column_name].median)  # 众数填充后计算\n",
    "    \n",
    "        Neg_group = select_df[select_df['bpCR'] == 0][column_name].tolist()\n",
    "        Pos_group = select_df[select_df['bpCR'] == 1][column_name].tolist()\n",
    "        # print('正态性X1/X2(>0.05表示满足正态性)',stats.shapiro(Neg_group)[1], stats.shapiro(Pos_group)[1])\n",
    "        equal_var = stats.levene(Neg_group, Pos_group)[1] > 0.05  # 判断是否方差齐性 >0.05是方差齐性的\n",
    "        \n",
    "        t_res = stats.ttest_ind(Neg_group, Pos_group, equal_var=equal_var)\n",
    "        # print('T检验p值',t_res[1])\n",
    "        u_res = stats.mannwhitneyu(Neg_group, Pos_group)\n",
    "        # print('U检验p值',u_res[1])\n",
    "        \n",
    "        if t_res[1] < 0.05:\n",
    "            contain_Tstat_var.append(column_name)\n",
    "            contain_Tstat_p.append(t_res[1])\n",
    "        else:\n",
    "            del_Tstat_var.append(column_name)\n",
    "        if u_res[1] < 0.05:\n",
    "            contain_Ustat_var.append(column_name)\n",
    "            contain_Ustat_p.append(u_res[1])\n",
    "        else:\n",
    "            del_Ustat_var.append(column_name)    \n",
    "            \n",
    "    return contain_Ustat_p, contain_Ustat_var, contain_Tstat_p, contain_Tstat_var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd7b6f82-c3a1-4595-a191-85a2ad5807e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lassocv_selector(contain_stat, X, y):\n",
    "    \"\"\"\n",
    "    LassoCV 特征筛选, 并以LR作为后续分类器评价筛选结果\n",
    "    \"\"\"\n",
    "    alphas = np.logspace(-5, 3, 50)\n",
    "    lassocv = LassoCV(alphas=alphas,cv=5, max_iter=100000)\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    lassocv.fit(X_std, y)\n",
    "    X_select = X[:, lassocv.coef_ != 0]\n",
    "    \n",
    "    # print('删除的特征为：', contain_stat[lassocv.coef_ == 0])\n",
    "    # print('最佳lambda:', lassocv.alpha_)\n",
    "    # print('最佳系数:', lassocv.coef_)   \n",
    "\n",
    "    # 用逻辑回归粗略验证剩余特征的结果\n",
    "    LR = LogisticRegression(penalty='l2', max_iter=10000)\n",
    "    print('输入模型的X shape', X_select.shape)\n",
    "    LR.fit(X_select, y)\n",
    "    score = cross_val_score(LR, X_select, y, cv=5, scoring='roc_auc').mean()\n",
    "    print('Score: ', score) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58945604-1b8b-4403-9c1d-88ad9904b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref_selector(estimator, n_features_to_select, contain_stat, X, y):\n",
    "    \"\"\"\n",
    "    ref_selector: 通过REF 特征递归消除法选择最佳的模型\n",
    "    \n",
    "    \"\"\"\n",
    "    rfe = RFE(estimator=estimator,     # 学习器\n",
    "                  n_features_to_select=n_features_to_select, \n",
    "                  step=1,           # 每次移除特征个数\n",
    "                  ).fit(X, y)\n",
    "\n",
    "    X_RFE = rfe.transform(X)\n",
    "    \n",
    "    select_features = np.array(contain_stat)[rfe.support_]\n",
    "    print(select_features)  #  选择的特征名称\n",
    "    score = cross_val_score(estimator, X_RFE, y, scoring='roc_auc').mean().round(7)\n",
    "    print(score)\n",
    "    \n",
    "    return score, X_RFE, select_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b4e0526-9181-4570-9f9c-50ae035a1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fef0ffc1-9278-46d5-b277-0d7ea4160f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_adc_zy = pd.read_csv(os.path.join(base_dir, 'zunyi_dec_adc_result.csv'), index_col=0)\n",
    "df_adc_syf1 = pd.read_csv(os.path.join(base_dir, 'syf_stage1_dec_adc_result.csv'), index_col=0)\n",
    "df_adc_syf2 = pd.read_csv(os.path.join(base_dir, 'syf_stage2_dec_adc_result.csv'), index_col=0)\n",
    "df_adc = pd.concat([df_adc_zy, df_adc_syf1, df_adc_syf2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f07f5f1-0e7a-48d1-8d1b-95d24372cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sd_dcereg_path = os.path.join(base_dir, 'sd_dec_dcereg_result.csv')\n",
    "# zy_dcereg_path = os.path.join(base_dir, 'zunyi_dcereg_result.csv')\n",
    "# syf1_dcereg_path = os.path.join(base_dir, 'syf_stage1_dcereg_result.csv')\n",
    "# syf2_dcereg_path = os.path.join(base_dir, 'syf_stage2_dcereg_result.csv')\n",
    "\n",
    "# df_dcereg_sd = pd.read_csv(sd_dcereg_path, index_col=0)\n",
    "# df_dcereg_zy = pd.read_csv(zy_dcereg_path, index_col=0)\n",
    "# df_dcereg_syf1 = pd.read_csv(syf1_dcereg_path, index_col=0)\n",
    "# df_dcereg_syf2 = pd.read_csv(syf2_dcereg_path, index_col=0)\n",
    "# df_dcereg = pd.concat([df_dcereg_sd, df_dcereg_zy, df_dcereg_syf1, df_dcereg_syf2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d64660a5-eacd-46f5-88e8-133cc34d8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取临床字段表,并将PCR列合并到组学的dataframe中\n",
    "df_clinical = pd.read_csv('判定_fill_df.csv', index_col=0)\n",
    "df_clinical.index.name = 'patient_id'\n",
    "df_pcr = df_clinical[['bpCR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a170a13e-c608-4d11-972c-a9fe6b83235c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((687, 1133), (727, 1132))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_adc_radiomics = pd.merge(df_adc, df_pcr, on='patient_id')\n",
    "df_adc_radiomics.shape, df_adc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1696c1c-a001-4ac6-a188-9d921d4503f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 166)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_p, U_var, T_p, T_var = stat_t_u(df_adc_radiomics)\n",
    "merge_var = [i for i in U_var if i in T_var]\n",
    "U_p, U_var, T_p, T_var,merge_var = np.array(U_p), np.array(U_var), np.array(T_p), np.array(T_var), np.array(merge_var)\n",
    "select_U_var = U_var[U_p < 0.05].tolist()\n",
    "select_T_var = T_var[T_p < 0.05].tolist()\n",
    "len(select_U_var), len(select_T_var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69b0e1d3-9279-45ec-8a02-d030f6940079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_adc_radiomics[df_adc_radiomics['bpCR'] == 1].var().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a1c24e6-f1dd-4efe-ba5e-ad9ef5a438e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_T_var = df_adc_radiomics.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59f498fb-15c1-48aa-bcef-6562e0fb9072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: []\n"
     ]
    }
   ],
   "source": [
    "# 计算每个特征与目标之间的斯皮尔曼相关系数\n",
    "correlations = df_adc_radiomics[select_U_var].apply(lambda x: x.corr(df_adc_radiomics['bpCR'], method='spearman'))\n",
    "# 筛选相关系数大于0.7的特征\n",
    "selected_features = correlations[correlations > 0.2].index.tolist()\n",
    "# 打印筛选结果\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "for idx in range(len(select_T_var)):\n",
    "    corr, p_value = spearmanr(df_adc_radiomics[select_T_var[idx]], df_adc_radiomics['bpCR'])\n",
    "    if abs(corr) > 0.2:\n",
    "        print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b5f3bc04-393a-44d5-9af9-6af2760d593f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8660254037844387"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_sperman_cor(X, Y):\n",
    "    return stats.spearmanr(X, Y)[0]\n",
    "X = [1, 2, 5]\n",
    "Y = [2, 2, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5a36eb01-4565-49b4-9d6c-ef1c3bc3f731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征总数： 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.033442354850656386, tolerance: 0.0066417241379310345\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1679540437726601, tolerance: 0.0066417241379310345\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.515938234030294, tolerance: 0.0066417241379310345\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8410592094586207, tolerance: 0.0066417241379310345\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8861838961686033, tolerance: 0.0066417241379310345\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.825498680553345, tolerance: 0.0066417241379310345\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009548241115695077, tolerance: 0.0066124137931034485\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01724945661254651, tolerance: 0.0066124137931034485\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.24897302152799483, tolerance: 0.0066124137931034485\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2103015543913358, tolerance: 0.0066124137931034485\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4469333720464448, tolerance: 0.0066124137931034485\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.383242832056997, tolerance: 0.0066124137931034485\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.221618499303677, tolerance: 0.0066124137931034485\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.850758925645792, tolerance: 0.0066124137931034485\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00999641169132559, tolerance: 0.006918620689655173\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0325363525936595, tolerance: 0.006918620689655173\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12973039297094857, tolerance: 0.006918620689655173\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06951192966856468, tolerance: 0.006918620689655173\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12573142364946222, tolerance: 0.006918620689655173\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.20172253564761178, tolerance: 0.006918620689655173\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.31644020851213384, tolerance: 0.006918620689655173\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1001812757661824, tolerance: 0.006918620689655173\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.488201323921686, tolerance: 0.006918620689655173\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04923728663997906, tolerance: 0.00671134020618557\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.24109534509918973, tolerance: 0.00671134020618557\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2742668413343097, tolerance: 0.00671134020618557\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6008012557365987, tolerance: 0.00671134020618557\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0813974985704888, tolerance: 0.00671134020618557\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2110535018348187, tolerance: 0.00671134020618557\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1492386528398768, tolerance: 0.006791752577319588\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5758221180940453, tolerance: 0.006791752577319588\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7213341688378208, tolerance: 0.006791752577319588\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7115295506454302, tolerance: 0.006791752577319588\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7979496939147595, tolerance: 0.006791752577319588\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.842056708418365, tolerance: 0.006791752577319588\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/app/data/anaconda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.25971590994947, tolerance: 0.006791752577319588\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入模型的X shape (363, 3)\n",
      "Score:  0.5977641521119782\n",
      "输入模型的X shape (363, 73)\n",
      "Score:  0.5599653164870556\n"
     ]
    }
   ],
   "source": [
    "df_test = df_dce_radiomics[select_T_var + ['bpCR']]\n",
    "features = df_test.columns[:-1]\n",
    "\n",
    "# 可以通过调节random_state 的数值，查看输出保留特征的稳定性\n",
    "shuffle_df = shuffle(df_test, random_state=1)\n",
    "print('特征总数：', len(shuffle_df.columns[:-1]))\n",
    "\n",
    "X = shuffle_df.values[:, :-1]\n",
    "y = shuffle_df.values[:, -1].astype(np.int8)   # 需要转换为int 类型，原来是object类型\n",
    "lassocv_selector(features, X, y)\n",
    "LR = LogisticRegression(penalty='l2', max_iter=10000)\n",
    "print('输入模型的X shape', X.shape)\n",
    "LR.fit(X, y)\n",
    "score = cross_val_score(LR, X, y, cv=5, scoring='roc_auc').mean()\n",
    "print('Score: ', score) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eea5b8a-0779-4b4c-bd8e-82922c9965b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2765d85-8796-4d85-9c47-cacec0bfa974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ SVC 0.1 =============================\n"
     ]
    }
   ],
   "source": [
    "init_C = [0.1, 0.5, 1.0, 1.5]\n",
    "\n",
    "for C in init_C:\n",
    "    clf_dict = {\n",
    "    'SVC': SVC(kernel=\"linear\", C=C, probability=True),  # 0.8\n",
    "    'LR_2': LogisticRegression(C=C, max_iter=1000), # 0.5\n",
    "    'LR_1': LogisticRegression(penalty='l1', solver='liblinear', C=C, max_iter=1000),  # 1.6\n",
    "\n",
    "    # 不使用树模型作为RFE特征选择的基础模型，一方面是由于数模型参数多；另一方面输出的结果不稳定\n",
    "    # 'GBDT': GradientBoostingClassifier(learning_rate=0.1, n_estimators=100, max_depth=C, random_state=2),  # 50, 2, 2\n",
    "    # 'RF': RandomForestClassifier(n_estimators=100, max_depth=C, random_state=2),  # 50, 4  2\n",
    "    # 'XGB': XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=C, random_state=2),  # 30, 2, 2\n",
    "    }\n",
    "\n",
    "\n",
    "    for  clf_name, clf in clf_dict.items():  # 遍历每一个分类器的RFE    \n",
    "\n",
    "        print('================', clf_name, C, '=============================')\n",
    "        scores_list = []\n",
    "\n",
    "        select_features_list = []\n",
    "        for n_features_to_select in range(1, X.shape[-1] + 1): # 12个可用特征\n",
    "            score, X_RFE, select_features = ref_selector(clf,  n_features_to_select, features, X, y)\n",
    "            scores_list.append(score)\n",
    "\n",
    "            select_features_list.append(select_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe151b-348e-4d96-9fa5-0d9628d3ad4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
